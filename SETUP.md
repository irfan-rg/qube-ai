# ğŸ¤– Qube Local AI Chatbot - Setup Guide

## ğŸ‰ **Welcome to Your FREE Local AI Chatbot!**

This chatbot runs completely locally using Ollama and Llama 3.2 - **NO API KEYS, NO QUOTAS, NO COSTS!**

## âš¡ **Quick Start (3 Steps)**

### 1. **Install Ollama** (Already Done! âœ…)
```bash
# Ollama is already installed on your system
# If you need to reinstall: winget install Ollama.Ollama
```

### 2. **Start Ollama & Download AI Model**
```bash
# Start Ollama service
ollama serve

# In a new terminal, download the AI model (this is a one-time setup)
ollama pull llama3.2:3b
```

### 3. **Start Your Chatbot**
```bash
# Install dependencies
npm install

# Start the chatbot server
npm start
```

### 4. **Open Your Chatbot**
- Go to `http://localhost:3000`
- Start chatting! ğŸš€

## ğŸ”§ **What's Different Now?**

### âœ… **Before (API-based)**:
- Required API keys
- Had usage quotas
- Cold start delays
- Monthly costs
- Internet dependency

### ğŸ¯ **Now (Local AI)**:
- âœ… **100% FREE** - No costs ever
- âœ… **NO QUOTAS** - Unlimited conversations
- âœ… **NO COLD STARTS** - Always instant responses
- âœ… **PRIVACY** - All data stays on your machine
- âœ… **OFFLINE** - Works without internet
- âœ… **FAST** - No network delays

## ğŸš€ **Features**

- **Smart Conversations**: Powered by Llama 3.2 3B model
- **Mobile Responsive**: Works perfectly on phones
- **Real-time**: Instant responses
- **Health Check**: Built-in status monitoring
- **Error Handling**: Clear error messages

## ğŸ› ï¸ **Troubleshooting**

### **"Ollama not running" Error**
```bash
# Start Ollama service
ollama serve

# Check if it's running
curl http://localhost:11434/api/tags
```

### **"Model not found" Error**
```bash
# Download the model
ollama pull llama3.2:3b

# List available models
ollama list
```

### **Server Won't Start**
```bash
# Install dependencies
npm install

# Check if port 3000 is free
netstat -an | findstr :3000
```

## ğŸ“Š **System Requirements**

- **RAM**: 4GB+ (model uses ~2GB)
- **Storage**: 2GB for the model
- **OS**: Windows 10/11 (already installed!)

## ğŸ¯ **Performance**

- **Response Time**: 1-3 seconds
- **Model Size**: ~2GB
- **Memory Usage**: ~2GB RAM
- **Concurrent Users**: Unlimited

## ğŸ”„ **Updating**

To update to newer models:
```bash
# Pull newer model
ollama pull llama3.2:latest

# Update MODEL_NAME in server.js
# Restart server
npm start
```

## ğŸ‰ **You're All Set!**

Your chatbot is now:
- âœ… **Completely Free**
- âœ… **Always Fast**
- âœ… **Privacy-Focused**
- âœ… **Offline Capable**

**Enjoy your unlimited AI conversations!** ğŸ¤–âœ¨
